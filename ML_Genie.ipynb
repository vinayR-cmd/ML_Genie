{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.metrics import accuracy_score, r2_score\n",
        "import joblib\n",
        "import streamlit as st\n",
        "\n",
        "def detect_task_type(y):\n",
        "    return 'classification' if y.dtype == 'object' or y.nunique() < 20 else 'regression'\n",
        "\n",
        "def preprocess_and_train(df, target_column):\n",
        "    X = df.drop(target_column, axis=1)\n",
        "    y = df[target_column]\n",
        "\n",
        "    task_type = detect_task_type(y)\n",
        "\n",
        "    num_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "    cat_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "    num_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    cat_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "\n",
        "    preprocessor = ColumnTransformer([\n",
        "        ('num', num_pipeline, num_features),\n",
        "        ('cat', cat_pipeline, cat_features)\n",
        "    ])\n",
        "\n",
        "    if task_type == 'classification':\n",
        "        models = {\n",
        "            'LogisticRegression': LogisticRegression(max_iter=1000),\n",
        "            'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
        "            'RandomForestClassifier': RandomForestClassifier(),\n",
        "            'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
        "            'KNeighborsClassifier': KNeighborsClassifier(),\n",
        "            'SVC': SVC()\n",
        "        }\n",
        "    else:\n",
        "        models = {\n",
        "            'LinearRegression': LinearRegression(),\n",
        "            'DecisionTreeRegressor': DecisionTreeRegressor(),\n",
        "            'RandomForestRegressor': RandomForestRegressor(),\n",
        "            'GradientBoostingRegressor': GradientBoostingRegressor(),\n",
        "            'KNeighborsRegressor': KNeighborsRegressor(),\n",
        "            'SVR': SVR()\n",
        "        }\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    results = {}\n",
        "    best_score = -np.inf\n",
        "    best_model_name = ''\n",
        "    best_model = None\n",
        "\n",
        "    for name, model in models.items():\n",
        "        pipe = Pipeline([\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('model', model)\n",
        "        ])\n",
        "\n",
        "        pipe.fit(X_train, y_train)\n",
        "        y_pred = pipe.predict(X_test)\n",
        "\n",
        "        score = accuracy_score(y_test, y_pred) if task_type == 'classification' else r2_score(y_test, y_pred)\n",
        "        results[name] = round(score * 100, 2)  # Convert to percentage\n",
        "\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_model_name = name\n",
        "            best_model = pipe\n",
        "\n",
        "    joblib.dump(best_model, 'best_model.pkl')\n",
        "    return best_model_name, results, best_model.predict(X), task_type\n",
        "\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"üìä ML Genie\")\n",
        "\n",
        "st.sidebar.markdown(\"## üöÄ Quick Start\")\n",
        "st.sidebar.markdown(\"\"\"\n",
        "1. Upload your CSV dataset\n",
        "2. Select target column\n",
        "3. Run analysis\n",
        "4. Download predictions\n",
        "\"\"\")\n",
        "\n",
        "st.sidebar.markdown(\"## üìã Supported Formats\")\n",
        "st.sidebar.markdown(\"\"\"\n",
        "- CSV files only\n",
        "- Numerical and categorical features\n",
        "- Classification and regression tasks\n",
        "\"\"\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"üìÇ Upload your dataset (.csv)\", type=[\"csv\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    if not uploaded_file.name.endswith('.csv'):\n",
        "        st.error(\"‚ùå The format is not supported. Please upload a CSV file.\")\n",
        "        st.stop()\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(uploaded_file)\n",
        "        st.write(\"### üîç Dataset Preview\", df.head())\n",
        "\n",
        "        target_column = st.selectbox(\"üéØ Select the target column:\", df.columns)\n",
        "\n",
        "        if st.button(\"üöÄ Run Analysis\"):\n",
        "            with st.spinner(\"Training models, please wait...\"):\n",
        "                best_model_name, results, predictions, task_type = preprocess_and_train(df, target_column)\n",
        "\n",
        "            st.success(f\"‚úÖ Best Model: {best_model_name} ({task_type.title()})\")\n",
        "            st.write(\"### üìà Model Performance (%):\")\n",
        "            st.dataframe(pd.DataFrame.from_dict(results, orient='index', columns=['Score']).sort_values(by='Score', ascending=False))\n",
        "\n",
        "            df['Predictions'] = predictions\n",
        "            st.download_button(\"üì• Download Predictions CSV\", data=df.to_csv(index=False), file_name=\"predictions.csv\")\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"üö´ Error reading file: {e}\")\n",
        "else:\n",
        "    st.info(\"üìÇ Please upload a CSV file to continue.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpr0Djar4Is7",
        "outputId": "845d30ef-f402-4b60-a9ef-7b1edc5b3e3b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPQF-mPLbAcV",
        "outputId": "ab693d0b-d731-49e0-ef02-84fa79e7b4ff"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.47.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.47.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.7.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.12)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken 30BSvhKS0UakM7ZXSv2i1dIo0wf_2F2vBDU86aSMsAJCachbM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEmN6QCtZhNV",
        "outputId": "203d0c59-bfbc-4de6-b4c6-9cbfc3e22bbe"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import threading\n",
        "\n",
        "def run_streamlit():\n",
        "  os.system('streamlit run app.py --server.port 8501')\n",
        "\n",
        "thread=threading.Thread(target=run_streamlit)\n",
        "thread.start()"
      ],
      "metadata": {
        "id": "f6MTxkyibFdO"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Close all open tunnels first\n",
        "ngrok.kill()  # This kills all active tunnels"
      ],
      "metadata": {
        "id": "bqUY-GtrbI2c"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import time\n",
        "\n",
        "time.sleep(5)\n",
        "public_url=ngrok.connect(8501)\n",
        "print('your streamlit app is live here: ',public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8dInx83bLQT",
        "outputId": "1bf638e8-5451-428c-8fa4-8fb4939dc6b6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your streamlit app is live here:  NgrokTunnel: \"https://193a03d22102.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}